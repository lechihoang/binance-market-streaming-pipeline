# Custom Airflow image with project dependencies + PySpark
FROM apache/airflow:2.7.3-python3.10

USER root

# Install system dependencies including Java for Spark
RUN apt-get update && apt-get install -y --no-install-recommends \
    gcc \
    g++ \
    openjdk-11-jre-headless \
    procps \
    && rm -rf /var/lib/apt/lists/*

# Set JAVA_HOME
ENV JAVA_HOME=/usr/lib/jvm/java-11-openjdk-arm64
ENV PATH="${JAVA_HOME}/bin:${PATH}"

USER airflow

# Install Python dependencies for the streaming pipeline + PySpark
RUN pip install --no-cache-dir \
    websockets>=12.0 \
    kafka-python-ng>=2.2.0 \
    pydantic>=2.0.0 \
    cityhash>=0.4.0 \
    orjson>=3.9.0 \
    redis>=5.0.0 \
    duckdb>=0.9.0 \
    pyarrow>=14.0.0 \
    pandas>=2.0.0 \
    numpy>=1.24.0 \
    python-snappy>=0.6.0 \
    pyspark==3.5.0 \
    minio>=7.2.0 \
    psycopg2-binary>=2.9.0
