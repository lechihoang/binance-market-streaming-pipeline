# =============================================================================
# Binance-Kafka Connector Configuration (Phase 1)
# =============================================================================

# WebSocket Configuration
BINANCE_WS_URL=wss://stream.binance.com:9443/stream
BINANCE_STREAMS=btcusdt@trade,ethusdt@trade,bnbusdt@trade,btcusdt@kline_1m,ethusdt@kline_1m,btcusdt@ticker
PING_INTERVAL_SECONDS=180
RECONNECT_MAX_DELAY_SECONDS=60
WS_CONNECTION_TIMEOUT=10

# Kafka Configuration (shared with Phase 2)
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_COMPRESSION=snappy
KAFKA_ACKS=1

# Kafka Topics
TOPIC_RAW_TRADES=raw_trades
TOPIC_RAW_KLINES=raw_klines
TOPIC_RAW_TICKERS=raw_tickers
TOPIC_PROCESSED_AGGREGATIONS=processed_aggregations
TOPIC_PROCESSED_INDICATORS=processed_indicators
TOPIC_ALERTS=alerts

# Batching Configuration
BATCH_SIZE=100
BATCH_TIMEOUT_MS=100
BATCH_CHECK_INTERVAL_MS=10

# =============================================================================
# PySpark Streaming Processor Configuration (Phase 2)
# =============================================================================

# Spark Configuration
SPARK_EXECUTOR_MEMORY=250m
SPARK_DRIVER_MEMORY=250m
SPARK_EXECUTOR_CORES=1
SPARK_SHUFFLE_PARTITIONS=2
SPARK_CHECKPOINT_LOCATION=/tmp/spark-checkpoints
SPARK_BACKPRESSURE_ENABLED=true

# Kafka Consumer Settings
KAFKA_MAX_RATE_PER_PARTITION=100
KAFKA_STARTING_OFFSETS=latest

# Redis Configuration
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=
REDIS_CANDLE_TTL_SECONDS=3600
REDIS_INDICATOR_TTL_SECONDS=3600
REDIS_ALERT_LIST_MAX_SIZE=1000

# DuckDB Configuration
DUCKDB_DATABASE_PATH=./data/streaming_data.duckdb
DUCKDB_TABLE_CANDLES=candles
DUCKDB_TABLE_INDICATORS=indicators
DUCKDB_TABLE_ALERTS=alerts

# Parquet Configuration
PARQUET_OUTPUT_PATH=./data/parquet_output
PARQUET_COMPRESSION=snappy
PARQUET_PARTITION_COLUMNS=date,symbol

# Logging
LOG_LEVEL=INFO
